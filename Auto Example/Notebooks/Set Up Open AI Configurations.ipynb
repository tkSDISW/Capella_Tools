{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b453c90d-bb21-412f-8299-126e367419c1",
   "metadata": {},
   "source": [
    "# ğŸ”§ Model Configuration Manager for RAG Analysis\n",
    "\n",
    "This notebook allows you to create, manage, and select between different **LLM model configurations** for use with tools like `ChatGPTAnalyzer`.\n",
    "\n",
    "Each configuration includes:\n",
    "- ğŸ¤– **Model name** (e.g., `gpt-4o`, `mistral-7b-instruct`, `llama3-70b-instruct`)\n",
    "- ğŸŒ **Base URL** (e.g., `https://api.openai.com/v1`, `http://localhost:8080/v1`)\n",
    "- ğŸ” **API Key** (e.g., `sk-...` or `ollama`, `sk-noauth`)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ—ƒï¸ Configuration Storage\n",
    "\n",
    "All configurations are stored in the following JSON file:\n",
    "\n",
    "```\n",
    "~/.secrets/model_configs.json\n",
    "```\n",
    "\n",
    "This file will look something like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"openai\": {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"base_url\": \"https://api.openai.com/v1\",\n",
    "    \"api_key\": \"sk-...\"\n",
    "  },\n",
    "  \"mistral\": {\n",
    "    \"model\": \"mistral-7b-instruct\",\n",
    "    \"base_url\": \"http://localhost:8080/v1\",\n",
    "    \"api_key\": \"sk-noauth\"\n",
    "  },\n",
    "  \"_default\": \"openai\"\n",
    "}\n",
    "```\n",
    "\n",
    "You can **manually edit or copy** this file if needed to:\n",
    "- Share configurations with others\n",
    "- Maintain consistent setups across environments\n",
    "- Set or change the default model (`\"_default\"` key)\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… How to Use This Notebook\n",
    "\n",
    "1. Run the notebook cells to:\n",
    "   - Add or update a named model configuration\n",
    "   - Optionally set it as the default\n",
    "\n",
    "2. Use your configurations in tools like `ChatGPTAnalyzer`:\n",
    "\n",
    "```python\n",
    "from Open_AI_RAG_manager import ChatGPTAnalyzer\n",
    "\n",
    "# Use specific model\n",
    "analyzer = ChatGPTAnalyzer.from_config(\"mistral\", yaml_content=my_yaml)\n",
    "\n",
    "# Or just use the default model\n",
    "analyzer = ChatGPTAnalyzer.from_config(yaml_content=my_yaml)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "> ğŸ’¡ Tip: You can define as many configurations as you like â€” great for testing different LLMs or backends like OpenAI, LM Studio, Ollama, and Hugging Face APIs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db977421-a5fe-4081-b95d-54f08af73cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ğŸ“¦ Saved Configurations (default: `gpt-oss-120b`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- `gpt-oss-120b` â†’ model: `gpt-oss-120b`, url: `https://api.siemens.com/llm`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ”– Enter configuration name (e.g., mistral):  gpt-4o\n",
      "ğŸ¤– Model name (e.g., mistral-7b-instruct):  gpt-4o\n",
      "ğŸŒ Base URL (e.g., http://localhost:8080/v1):  https://api.openai.com/v1\n",
      "ğŸ” API Key (or sk-noauth):  Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "â­ Set this config as default? (y/N):  y\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "âœ… **Configuration `gpt-4o` saved.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "ğŸŒŸ **Set as default configuration.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ğŸ“¦ Saved Configurations (default: `gpt-4o`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- `gpt-oss-120b` â†’ model: `gpt-oss-120b`, url: `https://api.siemens.com/llm`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- `gpt-4o` â†’ model: `gpt-4o`, url: `https://api.openai.com/v1`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "CONFIG_FILE = Path.home() / \".secrets\" / \"model_configs.json\"\n",
    "CONFIG_FILE.parent.mkdir(exist_ok=True)\n",
    "\n",
    "def load_configs():\n",
    "    if CONFIG_FILE.exists():\n",
    "        with CONFIG_FILE.open() as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_configs(configs):\n",
    "    with CONFIG_FILE.open(\"w\") as f:\n",
    "        json.dump(configs, f, indent=2)\n",
    "\n",
    "def create_or_update_config():\n",
    "    name = input(\"ğŸ”– Enter configuration name (e.g., mistral): \").strip()\n",
    "    model = input(\"ğŸ¤– Model name (e.g., mistral-7b-instruct): \").strip()\n",
    "    base_url = input(\"ğŸŒ Base URL (e.g., http://localhost:8080/v1): \").strip()\n",
    "    api_key = getpass(\"ğŸ” API Key (or sk-noauth): \").strip()\n",
    "    \n",
    "    configs = load_configs()\n",
    "    configs[name] = {\n",
    "        \"model\": model,\n",
    "        \"base_url\": base_url,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "\n",
    "    # Set as default?\n",
    "    make_default = input(\"â­ Set this config as default? (y/N): \").strip().lower() == \"y\"\n",
    "    if make_default:\n",
    "        configs[\"_default\"] = name\n",
    "\n",
    "    save_configs(configs)\n",
    "    display(Markdown(f\"âœ… **Configuration `{name}` saved.**\"))\n",
    "    if make_default:\n",
    "        display(Markdown(f\"ğŸŒŸ **Set as default configuration.**\"))\n",
    "\n",
    "def list_configs():\n",
    "    configs = load_configs()\n",
    "    if not configs:\n",
    "        display(Markdown(\"âŒ **No configurations found.**\"))\n",
    "        return\n",
    "\n",
    "    default_name = configs.get(\"_default\", \"None\")\n",
    "    display(Markdown(f\"### ğŸ“¦ Saved Configurations (default: `{default_name}`)\"))\n",
    "    for name, config in configs.items():\n",
    "        if name == \"_default\":\n",
    "            continue\n",
    "        display(Markdown(f\"- `{name}` â†’ model: `{config['model']}`, url: `{config['base_url']}`\"))\n",
    "\n",
    "\n",
    "list_configs()\n",
    "create_or_update_config()\n",
    "list_configs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f4b83-61da-40e5-80a4-71efda00714e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
